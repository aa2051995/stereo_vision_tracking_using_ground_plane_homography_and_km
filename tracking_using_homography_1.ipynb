{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4fa638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed.mansour\\Anaconda3\\envs\\ocr_cpu\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\ahmed.mansour\\Anaconda3\\envs\\ocr_cpu\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    SORT: A Simple, Online and Realtime Tracker\n",
    "    Copyright (C) 2016-2020 Alex Bewley alex@bewley.ai\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "# from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sympy\n",
    "from IPython.display import display\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2128d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objpoints[5][0],imgpoints[5][0]\n",
    "oj =  [[0,0],[91.4,0],[579.4,0],[579.4,579],[945.4,0],[945.4,579],\n",
    "             [1524,0],[579.4,1300],[701.4,1300],[823.4,1300],[945.4,1300]]\n",
    "# imgpo1 = [[432,288],[561,274],[596,338],[730,309]]\n",
    "imgpo1 =[[106,327],[218,313],[432,288],[596,338],[561,274],[730,309],\n",
    "              [705,256],[1087,492],[1116,457],[1143,427],[1159,402]]\n",
    "# imgpo2 = [[349,132],[293,124],[148,169],[259,120]]\n",
    "img = cv2.imread('basket0.png')\n",
    "# poitdist = cv2.undistortPoints(np.float32(imgpo1),K1,dist1)\n",
    "# poitdist.reshape(4,2).shape,np.float32(oj).shape\n",
    "H1 = cv2.findHomography(np.float32(imgpo1),np.float32(oj),0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3958a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpo2= [[596,283],[631,289],[733,308],[554,333],[855,330],[674,368],\n",
    "              [1183,392],[125,392],[135,415],[149,444],[166,482]]\n",
    "# imgpo2 = [[349,132],[293,124],[148,169],[259,120]]\n",
    "img = cv2.imread('basket1.png')\n",
    "# poitdist = cv2.undistortPoints(np.float32(imgpo1),K1,dist1)\n",
    "# poitdist.reshape(4,2).shape,np.float32(oj).shape\n",
    "\n",
    "H2 = cv2.findHomography(np.float32(imgpo2),np.float32(oj),0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8db352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f412f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "def linear_assignment(cost_matrix):\n",
    "  try:\n",
    "    import lap\n",
    "    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "    return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "  except ImportError:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    x, y = linear_sum_assignment(cost_matrix)\n",
    "    return np.array(list(zip(x, y)))\n",
    "\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "  \"\"\"\n",
    "  From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "  \"\"\"\n",
    "  bb_gt = np.expand_dims(bb_gt, 0)\n",
    "  bb_test = np.expand_dims(bb_test, 1)\n",
    "  \n",
    "  xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "  yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "  xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "  yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "  w = np.maximum(0., xx2 - xx1)\n",
    "  h = np.maximum(0., yy2 - yy1)\n",
    "  wh = w * h\n",
    "  o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "  return(o)  \n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "  \"\"\"\n",
    "  w = np.sqrt(x[2] * x[3])\n",
    "  h = x[2] / w\n",
    "  if(score==None):\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "  else:\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "  \"\"\"\n",
    "  Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "  \"\"\"\n",
    "  if(len(trackers)==0):\n",
    "    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "  iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "  if min(iou_matrix.shape) > 0:\n",
    "    a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "        matched_indices = np.stack(np.where(a), axis=1)\n",
    "    else:\n",
    "      matched_indices = linear_assignment(-iou_matrix)\n",
    "  else:\n",
    "    matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "  unmatched_detections = []\n",
    "  for d, det in enumerate(detections):\n",
    "    if(d not in matched_indices[:,0]):\n",
    "      unmatched_detections.append(d)\n",
    "  unmatched_trackers = []\n",
    "  for t, trk in enumerate(trackers):\n",
    "    if(t not in matched_indices[:,1]):\n",
    "      unmatched_trackers.append(t)\n",
    "\n",
    "  #filter out matched with low IOU\n",
    "  matches = []\n",
    "  for m in matched_indices:\n",
    "    if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "      unmatched_detections.append(m[0])\n",
    "      unmatched_trackers.append(m[1])\n",
    "    else:\n",
    "      matches.append(m.reshape(1,2))\n",
    "  if(len(matches)==0):\n",
    "    matches = np.empty((0,2),dtype=int)\n",
    "  else:\n",
    "    matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769688e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanBoxTracker(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox,match=False):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.time_since_update = 0\n",
    "    self.id = KalmanBoxTracker.count\n",
    "    self.start_frame = 0\n",
    "    KalmanBoxTracker.count += 1\n",
    "    self.history = []\n",
    "    self.history_pred = []\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    self.hits = 0\n",
    "    self.hit_streak = 0\n",
    "    self.age = 0\n",
    "    self.hasmatch = match\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.time_since_update = 0\n",
    "#     self.history = []\n",
    "#     self.history_pred = []\n",
    "    self.hits += 1\n",
    "    self.hit_streak += 1\n",
    "    self.kf.update(convert_bbox_to_z(bbox))\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    tt = convert_x_to_bbox(self.kf.x)\n",
    "    self.history_pred.append(tt)\n",
    "    return tt\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98daefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Sort(object):\n",
    "  def __init__(self,H1,H2, max_age=1, min_hits=3, iou_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Sets key parameters for SORT\n",
    "    \"\"\"\n",
    "    self.H1 = H1\n",
    "    self.H2 = H2\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers_first = []\n",
    "    self.trackers_second = []\n",
    "    self.trackers_del = []\n",
    "    self.trackers_del_sec = []\n",
    "    self.trks_ids_second = []\n",
    "    self.trks_ids_first = []\n",
    "    self.frame_count = 0\n",
    "    self.ids_count = 0\n",
    "    self.rem_track = 0\n",
    "#     inds = self.get_pairs_match(det1,det2,H1,H2)\n",
    "    \n",
    "#   def intiate_tracks():\n",
    "    \n",
    "  def get_pairs_match(self,det_first, det_second,threshold = 70.470,switch=False):\n",
    "    errors = []\n",
    "    inds = []\n",
    "   \n",
    "    for i in range(det_first.shape[0]):\n",
    "        errors = []\n",
    "        for j in range(det_second.shape[0]):\n",
    "            ss1,ss2=0,0\n",
    "            pt1 = np.array([(det_first[i][0] + det_first[i][2])/2,det_first[i][3],1])\n",
    "            if not switch:\n",
    "                ss1 = np.matmul(self.H1,pt1)\n",
    "            else:\n",
    "                ss1 = np.matmul(self.H2,pt1)\n",
    "            ss1 = ss1/ss1[2]\n",
    "            pt2 = np.array([(det_second[j][0] + det_second[j][2])/2,det_second[j][3],1])\n",
    "            if not switch:\n",
    "                ss2 = np.matmul(self.H2,pt2)\n",
    "            else:\n",
    "                ss2 = np.matmul(self.H1,pt2)\n",
    "            ss2 = ss2/ss2[2]\n",
    "            er = math.sqrt(math.pow(ss1[0]-ss2[0],2) + math.pow(ss1[1]-ss2[1],2))\n",
    "            errors.append(er)\n",
    "        indo =  np.argsort(errors) \n",
    "        if indo.shape[0]==1 and errors[indo[0]]<threshold:\n",
    "            inds.append((i,indo[0]))\n",
    "        if indo.shape[0] >1 and errors[indo[0]] < .75*errors[indo[1]]:# and errors[indo[0]]<threshold:\n",
    "            inds.append((i,indo[0]))\n",
    "       \n",
    "    return inds\n",
    "\n",
    "\n",
    "        \n",
    "  def update_stereo(self, dets_first=np.empty((0, 5)),dets_second=np.empty((0, 5)),frame_no=0):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks1 = np.zeros((len(self.trackers_first), 5))\n",
    "    new_tracks = 0\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks1):\n",
    "      pos = self.trackers_first[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]#[true_pos[0], true_pos[1], true_pos[2], true_pos[3], 0] \n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks1 = np.ma.compress_rows(np.ma.masked_invalid(trks1))\n",
    " \n",
    "    ###\n",
    "    trks2 = np.zeros((len(self.trackers_second), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks2):\n",
    "      pos = self.trackers_second[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]#[true_pos[0], true_pos[1], true_pos[2], true_pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks2 = np.ma.compress_rows(np.ma.masked_invalid(trks2))\n",
    "    matched1, unmatched_dets1, unmatched_trks1 = associate_detections_to_trackers(dets_first,trks1, self.iou_threshold)\n",
    "    matched2, unmatched_dets2, unmatched_trks2 = associate_detections_to_trackers(dets_second,trks2, self.iou_threshold)\n",
    "    \n",
    "    if len(trks1)>0 and len(unmatched_dets2)>0: \n",
    "        inds1 = self.get_pairs_match(dets_second[unmatched_dets2],trks1)\n",
    "        for i,j in inds1:\n",
    "             trk = KalmanBoxTracker(dets_second[unmatched_dets2[i],:],match=True)\n",
    "             trk.start_frame = frame_no\n",
    "             trk.id = self.trks_ids_first[j]\n",
    "             self.trackers_second.append(trk)\n",
    "             self.trks_ids_second.append(self.trks_ids_first[j])\n",
    "             new_tracks+=1\n",
    "             pt2 = np.array([(dets_second[unmatched_dets2[i],:][0] + dets_second[unmatched_dets2[i],:][2])/2,dets_second[unmatched_dets2[i],:][3],1])\n",
    "        if len(inds1)>0:\n",
    "            unmatched_dets2 = np.delete(unmatched_dets2,[i for i,j in inds1 ],0) \n",
    "            \n",
    "    if len(trks2)>0 and len(unmatched_dets1)>0:\n",
    "        inds2 = self.get_pairs_match(dets_first[unmatched_dets1],trks2)\n",
    "        for i,j in inds2:\n",
    "             trk = KalmanBoxTracker(dets_first[unmatched_dets1[i],:],match=True)\n",
    "             trk.start_frame = frame_no\n",
    "             trk.id = self.trks_ids_second[j]\n",
    "             self.trackers_first.append(trk)\n",
    "             self.trks_ids_first.append(self.trks_ids_second[j]) \n",
    "             new_tracks+=1\n",
    "             pt2 = np.array([(dets_first[unmatched_dets1[i],:][0] + dets_first[unmatched_dets1[i],:][2])/2,dets_first[unmatched_dets1[i],:][3],1])\n",
    "        if len(inds2)>0:\n",
    "            unmatched_dets1 = np.delete(unmatched_dets1,[i for i,j in inds2 ],0) \n",
    "\n",
    "    inds3 = []\n",
    "    if len(unmatched_dets2)>0 and len(unmatched_dets1)>0:\n",
    "        inds3 = self.get_pairs_match(dets_first[unmatched_dets1],dets_second[unmatched_dets2])\n",
    "    for i,j in inds3:\n",
    "        trk = KalmanBoxTracker(dets_first[unmatched_dets1[i],:],match=True)\n",
    "        trk.start_frame = frame_no\n",
    "        trk.id = self.ids_count\n",
    "        self.trackers_first.append(trk)\n",
    "        \n",
    "        trk = KalmanBoxTracker(dets_second[unmatched_dets2[j],:],match=True)\n",
    "        trk.start_frame = frame_no\n",
    "        trk.id = self.ids_count\n",
    "        self.trackers_second.append(trk)   \n",
    "        \n",
    "        self.trks_ids_first.append(self.ids_count)\n",
    "        self.trks_ids_second.append(self.ids_count)\n",
    "        self.ids_count+=1\n",
    "        new_tracks+=1\n",
    "    match_inds1  = [t for t,v in inds3 ]\n",
    "    for i in unmatched_dets1:\n",
    "        if i not in match_inds1:\n",
    "            trk = KalmanBoxTracker(dets_first[i,:])\n",
    "            trk.start_frame = frame_no\n",
    "            trk.id = self.ids_count\n",
    "            self.trackers_first.append(trk) \n",
    "            self.trks_ids_first.append(self.ids_count)\n",
    "            self.ids_count+=1\n",
    "            new_tracks+=1\n",
    "    match_inds2   = [v for t,v in inds3 ]\n",
    "    for i in unmatched_dets2:\n",
    "        if i not in match_inds2:\n",
    "            trk = KalmanBoxTracker(dets_second[i,:])\n",
    "            trk.start_frame = frame_no\n",
    "            trk.id = self.ids_count\n",
    "            self.trackers_second.append(trk)  \n",
    "            self.trks_ids_second.append(self.ids_count)\n",
    "            self.ids_count+=1\n",
    "            new_tracks+=1\n",
    "            \n",
    "    for m in matched1:\n",
    "          self.trackers_first[m[1]].update(dets_first[m[0], :])\n",
    "    for m in matched2:\n",
    "          self.trackers_second[m[1]].update(dets_second[m[0], :])\n",
    "            \n",
    "    i = len(self.trackers_first)\n",
    "    for trk in reversed(self.trackers_first):\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers_del.append(self.trackers_first[i])\n",
    "          self.trackers_first.pop(i)\n",
    "          self.trks_ids_first.pop(i) \n",
    "          \n",
    "          self.rem_track+=1\n",
    "    i = len(self.trackers_second)\n",
    "    for trk in reversed(self.trackers_second):\n",
    "        i -= 1\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers_del_sec.append(self.trackers_second[i])\n",
    "          self.trackers_second.pop(i)\n",
    "          self.trks_ids_second.pop(i)  \n",
    "          self.rem_track+=1\n",
    "    if(len(ret)>0):\n",
    "      return np.concatenate(ret)\n",
    "\n",
    "    return np.empty((0,5))\n",
    "\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.max_age= 30\n",
    "        self.min_hits=3\n",
    "        self.iou_threshold=.3\n",
    "        self.phase='train'\n",
    "        self.seq_path = 'cam.txt'\n",
    "        self.display = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99041c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "display = args.display\n",
    "phase = args.phase\n",
    "total_time = 0.0\n",
    "total_frames = 0\n",
    "seq_dets_first = np.loadtxt('cam1_basket1.txt', delimiter=' ')\n",
    "seq_dets_second = np.loadtxt('cam2_basket2.txt', delimiter=' ')\n",
    "mot_tracker = Sort(H1,H2,max_age=args.max_age, \n",
    "                       min_hits=args.min_hits,\n",
    "                       iou_threshold=args.iou_threshold)\n",
    "\n",
    "for frame in range(int(seq_dets_first[:,0].max())):\n",
    "#     frame += 0 #detection and frame numbers begin at 1\n",
    "    dets_first = seq_dets_first[seq_dets_first[:, 0]==frame, 2:7]\n",
    "    #     print(dets_first)\n",
    "    #     dets_first[:, 2:4] += dets_first[:, 0:2] #convert to [x1,y1,w,h] to [x1,y1,x2,y2]\n",
    "    dets_second = seq_dets_second[seq_dets_second[:, 0]==frame, 2:7]\n",
    "    #     dets_second[:, 2:4] += dets_second[:, 0:2] #convert to [x1,y1,w,h] to [x1,y1,x2,y2]\n",
    "    #     total_frames += 1\n",
    "    mot_tracker.update_stereo(dets_first,dets_second,frame)\n",
    "    #trying with 15 second only\n",
    "    if frame==30*15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bca6733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skvideo.io\n",
    "img = cv2.imread('frame0.png')\n",
    "vcap1 = cv2.VideoCapture(r\"C:\\Users\\ahmed.mansour\\Downloads\\vid1.mp4\")\n",
    "out_video = None\n",
    "frame_no = 14*30\n",
    "vcap1.set(1,frame_no)\n",
    "img_num =0\n",
    "while(1):\n",
    "    ret, img1 = vcap1.read()\n",
    "    if out_video is  None:\n",
    "        out_video =  np.empty([30*15,img1.shape[0],img1.shape[1], 3], dtype = np.uint8)\n",
    "        out_video =  out_video.astype(np.uint8)\n",
    "    for i in range(len(mot_tracker.trackers_first)):\n",
    "      max_ind = len(mot_tracker.trackers_first[i].history)+ mot_tracker.trackers_first[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_first[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_first[i].history[img_num-mot_tracker.trackers_first[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255,0,0))\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trks_ids_first[i]), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "    \n",
    "    for i in range(len(mot_tracker.trackers_del)):\n",
    "      max_ind = len(mot_tracker.trackers_del[i].history)+ mot_tracker.trackers_del[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_del[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_del[i].history[img_num-mot_tracker.trackers_del[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255,0,0))\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trackers_del[i].id), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "    out_video[img_num] = img1\n",
    "    img_num+=1\n",
    "    if img_num==30*15:\n",
    "        break\n",
    "\n",
    "# Writes the the output image sequences in a video file\n",
    "skvideo.io.vwrite(\"video_no10.mp4\", out_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c553fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skvideo.io\n",
    "vcap1 = cv2.VideoCapture(r\"C:\\Users\\ahmed.mansour\\Downloads\\video22.mp4\")\n",
    "out_video = None\n",
    "frame_no = (3*60+43)*30\n",
    "vcap1.set(1,frame_no)\n",
    "img_num =0\n",
    "while(1):\n",
    "    ret, img1 = vcap1.read()\n",
    "    if out_video is  None:\n",
    "        out_video =  np.empty([30*15,img1.shape[0],img1.shape[1], 3], dtype = np.uint8)\n",
    "        out_video =  out_video.astype(np.uint8)\n",
    "    for i in range(len(mot_tracker.trackers_second)):\n",
    "      max_ind = len(mot_tracker.trackers_second[i].history)+ mot_tracker.trackers_second[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_second[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_second[i].history[img_num-mot_tracker.trackers_second[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255,0,0))\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trks_ids_second[i]), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 3)\n",
    "    out_video[img_num] = img1\n",
    "    img_num+=1\n",
    "    if img_num==30*15:\n",
    "        break\n",
    "\n",
    "# Writes the the output image sequences in a video file\n",
    "skvideo.io.vwrite(\"video_1_n10.mp4\", out_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3055d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detctions_tracking\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "vcap1 = cv2.VideoCapture(r\"C:\\Users\\ahmed.mansour\\Downloads\\videoreal.mp4\")\n",
    "out_video = None\n",
    "frame_no = 0#14*30\n",
    "vcap1.set(1,frame_no)\n",
    "img_num =0\n",
    "while(1):\n",
    "    ret, img1 = vcap1.read()\n",
    "    if out_video is  None:\n",
    "        out_video =  np.empty([30*15,img1.shape[0],img1.shape[1], 3], dtype = np.uint8)\n",
    "        out_video =  out_video.astype(np.uint8)\n",
    "    for i in range(len(mot_tracker.trackers_first)):\n",
    "      max_ind = len(mot_tracker.trackers_first[i].history_pred) + mot_tracker.trackers_first[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_first[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_first[i].history_pred[img_num-mot_tracker.trackers_first[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255,165,0),2)\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trackers_first[i].id), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,165,0), 3)\n",
    "    for i in range(len(mot_tracker.trackers_del)):\n",
    "      max_ind = len(mot_tracker.trackers_del[i].history_pred) + mot_tracker.trackers_del[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_del[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_del[i].history_pred[img_num-mot_tracker.trackers_del[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255,165,0),3)\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trackers_del[i].id), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,165,0), 3)\n",
    "    out_video[img_num] = img1\n",
    "    img_num+=1\n",
    "    if img_num==30*15:\n",
    "        break\n",
    "\n",
    "# Writes the the output image sequences in a video file\n",
    "skvideo.io.vwrite(\"video_real_tracking.mp4\", out_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7591aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detctions_tracking\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "img = cv2.imread('frame0.png')\n",
    "vcap1 = cv2.VideoCapture(r\"C:\\Users\\ahmed.mansour\\Downloads\\videoreal2.mp4\")\n",
    "out_video = None\n",
    "frame_no = 0#14*30\n",
    "vcap1.set(1,frame_no)\n",
    "img_num =0\n",
    "while(1):\n",
    "    ret, img1 = vcap1.read()\n",
    "    if out_video is  None:\n",
    "        out_video =  np.empty([30*15,img1.shape[0],img1.shape[1], 3], dtype = np.uint8)\n",
    "        out_video =  out_video.astype(np.uint8)\n",
    "    for i in range(len(mot_tracker.trackers_second)):\n",
    "      max_ind = len(mot_tracker.trackers_second[i].history_pred) + mot_tracker.trackers_second[i].start_frame \n",
    "      if img_num>=mot_tracker.trackers_second[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_second[i].history_pred[img_num-mot_tracker.trackers_second[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255, 165, 0))\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trackers_second[i].id), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 165, 0), 3)\n",
    "    for i in range(len(mot_tracker.trackers_del_sec)):\n",
    "      max_ind = len(mot_tracker.trackers_del_sec[i].history_pred) + mot_tracker.trackers_del_sec[i].start_frame\n",
    "      if img_num>=mot_tracker.trackers_del_sec[i].start_frame \\\n",
    "        and max_ind > img_num:\n",
    "          pt1 = mot_tracker.trackers_del_sec[i].history_pred[img_num-mot_tracker.trackers_del_sec[i].start_frame][0]\n",
    "          img1 = cv2.rectangle(img1,(int(pt1[0]),int(pt1[1])),(int(pt1[2]),int(pt1[3])), (255, 165, 0))\n",
    "          img1 = cv2.putText(img1, str(mot_tracker.trackers_del_sec[i].id), (int(pt1[0]),int(pt1[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 165, 0), 3)\n",
    "    out_video[img_num] = img1\n",
    "    img_num+=1\n",
    "    if img_num==30*15:\n",
    "        break\n",
    "\n",
    "# Writes the the output image sequences in a video file\n",
    "skvideo.io.vwrite(\"video_real_tracking2.mp4\", out_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dc569805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "42379461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
